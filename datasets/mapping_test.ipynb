{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2949695f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def csv_loader(drive, type):\n",
    "    if type == 'train':\n",
    "        data = pd.read_csv(f\"{drive}:\\\\python__\\\\Final\\\\sample.csv\")\n",
    "    else:\n",
    "        data = pd.read_csv(f\"{drive}:\\\\python__\\\\Final\\\\valid.csv\")\n",
    "    \n",
    "    if drive == 'd':\n",
    "        data.name = data.name.str.replace(\"E\",\"D\")\n",
    "    \n",
    "    del data['Unnamed: 0']\n",
    "    print(\"csv파일 로드 완료\")\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e38f811c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv파일 로드 완료\n"
     ]
    }
   ],
   "source": [
    "data = csv_loader('e','valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc30f647",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "class dataset():\n",
    "\n",
    "    def data_storage(drive, data, start, end):\n",
    "        drive = drive.upper()\n",
    "\n",
    "        if len(data) > 100000:\n",
    "            folder_name = 'train'\n",
    "        else:\n",
    "            folder_name = 'valid'\n",
    "\n",
    "        for i,j in zip(list(data.name)[start:end], range(start,end)):\n",
    "            img = Image.open(i)\n",
    "            img = img.resize((50,50))\n",
    "            y = np.array(img)  # 이미지 -> 넘파이\n",
    "\n",
    "            scaled_y0 = y[:,:,0]\n",
    "            # scaled_y1 = y[:,:,1]\n",
    "            # scaled_y2 = y[:,:,2]\n",
    "\n",
    "            scaled_y0[(scaled_y0 >= 220)] = 255\n",
    "            # scaled_y1[(scaled_y1 >= 220)] = 255\n",
    "            # scaled_y2[(scaled_y2 >= 220)] = 255\n",
    "\n",
    "            scaled_y0[(scaled_y0 < 220)] = 0\n",
    "            # scaled_y1[(scaled_y1 < 220)] = 0\n",
    "            # scaled_y2[(scaled_y2 < 220)] = 0\n",
    "\n",
    "            scaled_y0 = torch.from_numpy(scaled_y0)\n",
    "            # scaled_y1 = torch.from_numpy(scaled_y1)\n",
    "            # scaled_y2 = torch.from_numpy(scaled_y2)\n",
    "\n",
    "            scaled_y0 = scaled_y0.numpy()\n",
    "\n",
    "            img_scaled_y = Image.fromarray(scaled_y0) # NumPy array to PIL image\n",
    "            \n",
    "            img_scaled_y.save(f'./{folder_name}_data/{j}.png','png')\n",
    "            \n",
    "            if j % 3000 == 0:\n",
    "                print(f\"{j}개째 완료\")\n",
    "            \n",
    "        print(f\"{end}개 완료\")\n",
    "\n",
    "    \n",
    "    def data_ready(drive, data):\n",
    "        drive = drive.upper()\n",
    "        \n",
    "        if len(data) > 100000:\n",
    "            folder_name = 'train'\n",
    "        else:\n",
    "            folder_name = 'valid'\n",
    "        \n",
    "        img_path_list = []\n",
    "        for i in range(len(os.listdir(f\"{drive}:\\\\python__\\\\Final\\\\{folder_name}_data\\\\\"))):\n",
    "            img_name = f\"{i}.png\"\n",
    "            img_path = os.path.join(f\"{drive}:\\\\python__\\\\Final\\\\{folder_name}_data\\\\\", img_name)\n",
    "            img_path_list.append(img_path)\n",
    "        img_path_list\n",
    "\n",
    "        # 데이터셋 텐서형태로 stack -> MNIST에서 tran.data와 같은 형태\n",
    "        out_list = []\n",
    "        for i in range(len(img_path_list)):\n",
    "            img = Image.open(img_path_list[i])\n",
    "#             img = img.resize((50,50))\n",
    "            y = np.array(img)  # 이미지 -> 넘파이\n",
    "            x = torch.from_numpy(y) # 넘파이 -> 텐서\n",
    "\n",
    "            out_list.append(x)\n",
    "            if i % 10000 == 0:\n",
    "                print(f\"{i}까지 진행됨.\")\n",
    "            \n",
    "        train_data = torch.stack(out_list, dim = 0)\n",
    "\n",
    "        print(\"데이터 구축 완료\")\n",
    "        print(train_data.size())\n",
    "        \n",
    "        return train_data\n",
    "        \n",
    "    \n",
    "    def save_data_npy(data, label):\n",
    "        if len(data) > 100000:\n",
    "            folder_name = 'train'\n",
    "        else:\n",
    "            folder_name = 'valid'\n",
    "            \n",
    "        # 텐서를 외부파일로저장\n",
    "        a = data\n",
    "        a_1 = label\n",
    "        \n",
    "        a_np = a.numpy()\n",
    "        a_np_1 = a_1.numpy()\n",
    "        \n",
    "        np.save(f'{folder_name}_data', a_np)\n",
    "        np.save(f'{folder_name}_target', a_np_1)\n",
    "        \n",
    "        np_load = np.load(f'{folder_name}_data.npy')\n",
    "        np_load_1 = np.load(f'{folder_name}_target.npy')\n",
    "        \n",
    "        result = torch.from_numpy(np_load)\n",
    "        result_1 = torch.from_numpy(np_load_1)\n",
    "        \n",
    "        return result, result_1\n",
    "    \n",
    "    \n",
    "    def load_data_npy(data, label):\n",
    "        # 외부파일을 텐서로 불러오기\n",
    "        np_load = np.load(data)\n",
    "        np_load_1 = np.load(label)\n",
    "        \n",
    "        result = torch.from_numpy(np_load)\n",
    "        result_1 = torch.from_numpy(np_load_1)\n",
    "        \n",
    "        return result, result_1\n",
    "\n",
    "    \n",
    "    def label_loader(data):\n",
    "        if len(data) > 100000:\n",
    "            type_data = train_data\n",
    "            type_target = train_target\n",
    "        else:\n",
    "            type_data = valid_data\n",
    "            type_target = valid_target\n",
    "            \n",
    "        target = data.label_index[:len(type_data)]\n",
    "        type_target = torch.from_numpy(target.values)\n",
    "        \n",
    "        print(\"label 구축 완료\")\n",
    "        print(type_target.size())\n",
    "        \n",
    "        return type_target\n",
    "        \n",
    "        \n",
    "    def plot(type, index):\n",
    "        if type == 'valid':\n",
    "            type_data = valid_data\n",
    "        else:\n",
    "            type_data = train_data\n",
    "            \n",
    "        x = type_data[index]\n",
    "        img = (np.array(x.detach().cpu(), dtype='float'))\n",
    "\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4fcadcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,train_target = dataset.load_data_npy('train_data.npy', 'train_target.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c418ceb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data,valid_target = dataset.load_data_npy('valid_data.npy', 'valid_target.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f403ece",
   "metadata": {},
   "source": [
    "# 함수 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f85578f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "def check_mapping(index, type):\n",
    "    if type == 'valid':\n",
    "        type_data = valid_data\n",
    "        type_target = valid_target\n",
    "    else:\n",
    "        type_data = train_data\n",
    "        type_target = train_target\n",
    "    \n",
    "    print(\"index : \"+ str(index))\n",
    "    print(\"\")\n",
    "    print(\"##  csv 파일  ##\")\n",
    "    print(data.name[index])\n",
    "    print(data.label[index])\n",
    "    print()\n",
    "    print(\"##  npy 파일  ##\")\n",
    "    print(type_data[index])\n",
    "    print(type_target[index])\n",
    "    \n",
    "    print(data[data.label_index==(type_target[index].item())].label.iloc[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ed2d6d17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index : 31532\n",
      "\n",
      "##  csv 파일  ##\n",
      "E:\\다양한 형태의 한글 문자 OCR\\Validation\\[원천]validation_필기체\\1.글자\\130\\15230006065.jpg\n",
      "뢨\n",
      "\n",
      "##  npy 파일  ##\n",
      "tensor([[255, 255, 255,  ..., 255, 255, 255],\n",
      "        [255, 255, 255,  ..., 255, 255, 255],\n",
      "        [255, 255, 255,  ..., 255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255,  ..., 255, 255, 255],\n",
      "        [255, 255, 255,  ..., 255, 255, 255],\n",
      "        [255, 255, 255,  ..., 255, 255, 255]], dtype=torch.uint8)\n",
      "tensor(715)\n",
      "뢨\n"
     ]
    }
   ],
   "source": [
    "check_mapping(31532,'valid')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
